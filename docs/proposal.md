1. The Single Genuine Problem: "Shadow Logic Hijacking"AI agents are being "gaslit" by indirect prompt injections. While tools like Azure AI Content Safety block obvious attacks, they miss Shadow Logic Hijacking—where a hacker embeds subtle instructions in documents (like a fake invoice) that don't violate safety filters but fundamentally alter the agent's intent.The Critical Gaps:The Intent Drift: Existing tools check if a prompt is bad. They don't check if the agent’s reasoning is still aligned with the corporate mission.The Compliance Void: There is no "black box" recorder for AI reasoning that can hold up in a court of law or an insurance audit.2. The Solution: Contextual Tiered AttestationVanguard Protocol is a Forensic Reasoning Firewall. It doesn't just look for bad words; it audits the Semantic Delta between the Agent's original mission and its proposed action, enriched by real-time business context.Addressing the Flaws:Fixing Latency (The Tiered Auditor): To prevent business slowdown, Vanguard operates in two modes:Asynchronous (Background): Constant auditing for low-risk tasks (e.g., drafting emails).Synchronous (Gatekeeper): A mandatory "Stop-and-Attest" gate for high-stakes actions (e.g., wire transfers > $10,000).Fixing Accuracy (Context Injection): Instead of simple string-to-string similarity, Vanguard fetches "Trust Baselines" (historical vendor data, anomaly scores) before the audit, ensuring the model knows that "Invoice #8831" is unexpected.3. Step-by-Step Technical Implementation (MVP)Step 1: The Reasoning Capture (Azure AI Studio)The AI Agent's "Chain of Thought" is intercepted using Azure AI Studio Prompt Flow. This captures the agent's step-by-step logic before it executes an API call.Step 2: Contextual Enrichment (Azure AI Search)Vanguard queries an Azure AI Search index containing "Immutable Business Policies" and "Historical Baselines" (e.g., a whitelist of approved vendors). This data is injected into the auditor's prompt to prevent false positives.Step 3: Independent Audit (Azure OpenAI GPT-4o-mini)The system sends the agent's logic + business context to a GPT-4o-mini instance.The Task: Calculate a Semantic Delta Score ($0.0$ to $1.0$).The Logic: "Does this action ($A$) deviate from Policy ($P$) given Context ($C$)?"Step 4: Immutable Record (Azure Confidential Ledger)The final decision, the audit trail, and the "Reasoning Hash" are written to Azure Confidential Ledger. This uses blockchain-backed storage to ensure that even a system administrator cannot delete proof of a hijacked intent.Step 5: Inclusive Alerting (Azure AI Speech & Vision)If the Delta Score exceeds the threshold (e.g., $>0.7$):Audio: Azure AI Speech generates a priority voice alert for the admin.Visual: The dashboard uses high-contrast, color-blind-friendly UI (tested via Azure AI Vision for accessibility compliance).
